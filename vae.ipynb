{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import lightning as pl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])\n",
    "# transform = transforms.Compose([transforms.Grayscale(3), transforms.ToTensor(), transforms.Resize([24,24])])\n",
    "\n",
    "# we ignore object detection annotations by setting target_transform to return 0\n",
    "train_dataset = MNIST(\n",
    "    \"data\",\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    \"data\",\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pl_bolts.models.autoencoders.components import (\n",
    "#     resnet18_decoder,\n",
    "#     resnet18_encoder,\n",
    "# )\n",
    "\n",
    "# class VAE(pl.LightningModule):\n",
    "#     def __init__(self, enc_out_dim=512, latent_dim=256, input_height=32):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.save_hyperparameters()\n",
    "\n",
    "#         # encoder, decoder\n",
    "#         self.encoder = resnet18_encoder(False, False)\n",
    "#         self.decoder = resnet18_decoder(\n",
    "#             latent_dim=latent_dim,\n",
    "#             input_height=input_height,\n",
    "#             first_conv=False,\n",
    "#             maxpool1=False\n",
    "#         )\n",
    "\n",
    "#         # distribution parameters\n",
    "#         self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
    "#         self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
    "\n",
    "#         # for the gaussian likelihood\n",
    "#         self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "#     def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "#         scale = torch.exp(logscale)\n",
    "#         mean = x_hat\n",
    "#         dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "#         # measure prob of seeing image under p(x|z)\n",
    "#         log_pxz = dist.log_prob(x)\n",
    "#         return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "#     def kl_divergence(self, z, mu, std):\n",
    "#         # --------------------------\n",
    "#         # Monte carlo KL divergence\n",
    "#         # --------------------------\n",
    "#         # 1. define the first two probabilities (in this case Normal for both)\n",
    "#         p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "#         q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "#         # 2. get the probabilities from the equation\n",
    "#         log_qzx = q.log_prob(z)\n",
    "#         log_pz = p.log_prob(z)\n",
    "\n",
    "#         # kl\n",
    "#         kl = (log_qzx - log_pz)\n",
    "#         kl = kl.sum(-1)\n",
    "#         return kl\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, _ = batch\n",
    "#         # encode x to get the mu and variance parameters\n",
    "#         x_encoded = self.encoder(x)\n",
    "#         mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "#         # sample z from q\n",
    "#         std = torch.exp(log_var / 2)\n",
    "#         q = torch.distributions.Normal(mu, std)\n",
    "#         z = q.rsample()\n",
    "\n",
    "#         # decoded\n",
    "#         x_hat = self.decoder(z)\n",
    "\n",
    "#         # reconstruction loss\n",
    "#         recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "#         # kl\n",
    "#         kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "#         # elbo\n",
    "#         elbo = (kl - recon_loss)\n",
    "#         elbo = elbo.mean()\n",
    "\n",
    "#         self.log_dict({\n",
    "#             'elbo': elbo,\n",
    "#             'kl': kl.mean(),\n",
    "#             'recon_loss': recon_loss.mean(),\n",
    "#             'reconstruction': recon_loss.mean(),\n",
    "#             'kl': kl.mean(),\n",
    "#         })\n",
    "\n",
    "#         return elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import os\n",
    "from typing import Optional\n",
    "from collections import namedtuple\n",
    "\n",
    "CustomTransform = namedtuple(\"CustomTransform\", [\"custom_resize\", \"custom_normalize\"])\n",
    "\n",
    "class Stack(nn.Module):\n",
    "    def __init__(self, channels, height, width):\n",
    "        super(Stack, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), self.channels, self.height, self.width)\n",
    "\n",
    "\n",
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 latent_dim:int,\n",
    "                 input_height:int,\n",
    "                 input_width:int,\n",
    "                 input_channels:int,\n",
    "                 lr: float,\n",
    "                 batch_size: int,\n",
    "                 save_path: Optional[str] = None, **kwargs):\n",
    "        \"\"\"Init function for the VAE\n",
    "        Args:\n",
    "        latent_dim (int): Latent Hidden Size\n",
    "        reconstruction loss vs KL-Divergence Loss\n",
    "        lr (float): Learning Rate, will not be used if auto_lr_find is used.\n",
    "        dataset (Optional[str]): Dataset to used\n",
    "        save_path (Optional[str]): Path to save images\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        ENC_OUT_DIM = 128\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_channels*input_height*input_width, 392), nn.BatchNorm1d(392), nn.LeakyReLU(0.1),\n",
    "            nn.Linear(392, 196), nn.BatchNorm1d(196), nn.LeakyReLU(0.1),\n",
    "            nn.Linear(196, 128), nn.BatchNorm1d(128), nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, ENC_OUT_DIM)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128), nn.BatchNorm1d(128), nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 196), nn.BatchNorm1d(196), nn.LeakyReLU(0.1),\n",
    "            nn.Linear(196, 392), nn.BatchNorm1d(392), nn.LeakyReLU(0.1),\n",
    "            nn.Linear(392, input_channels*input_height*input_width),\n",
    "            nn.Sigmoid(),\n",
    "            Stack(input_channels, input_height, input_width),\n",
    "        )\n",
    "\n",
    "        self.hidden2mu = nn.Linear(ENC_OUT_DIM, latent_dim)\n",
    "        self.hidden2log_var = nn.Linear(ENC_OUT_DIM, latent_dim)\n",
    "\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        hidden = self.encoder(x)\n",
    "        mu = self.hidden2mu(hidden)\n",
    "        log_var = self.hidden2log_var(hidden)\n",
    "        return mu, log_var\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def reparametrize(self, mu, log_var):\n",
    "        # Reparametrization Trick to allow gradients to backpropagate from the\n",
    "        # stochastic part of the model\n",
    "        sigma = torch.exp(0.5*log_var)\n",
    "        z = torch.randn_like(sigma)\n",
    "        return mu + sigma*z\n",
    "\n",
    "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "        scale = torch.exp(logscale)\n",
    "        mean = x_hat\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "        # measure prob of seeing image under p(x|z)\n",
    "        log_pxz = dist.log_prob(x)\n",
    "\n",
    "        return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        mu, log_var = self.encode(x)\n",
    "        std = torch.exp(log_var / 2)\n",
    "\n",
    "        #Sample from distribution\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        #Push sample through decoder\n",
    "        x_hat = self.decode(z)\n",
    "\n",
    "        return mu, std, z, x_hat\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        x, _ = batch\n",
    "\n",
    "        mu, std, z, x_hat = self.forward(x)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "        #expectation under z of the kl divergence between q(z|x) and\n",
    "        #a standard normal distribution of the same shape\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log('train_kl_loss', kl.mean(), on_step=True,\n",
    "                 on_epoch=True, prog_bar=False)\n",
    "        self.log('train_recon_loss', recon_loss.mean(), on_step=True,\n",
    "                 on_epoch=True, prog_bar=False)\n",
    "        self.log('train_loss', elbo, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # train_images = make_grid(x[:16]).cpu().numpy()\n",
    "        return elbo\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        x, _ = batch\n",
    "\n",
    "        mu, std, z, x_hat = self.forward(x)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "        #expectation under z of the kl divergence between q(z|x) and\n",
    "        #a standard normal distribution of the same shape\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = kl - recon_loss\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log('val_kl_loss', kl.mean(), on_step=False, on_epoch=True)\n",
    "        self.log('val_recon_loss', recon_loss.mean(), on_step=False, on_epoch=True)\n",
    "        self.log('val_loss', elbo, on_step=False, on_epoch=True)\n",
    "\n",
    "        self.logger.experiment.add_image('Normalized Inputs', make_grid(x[:8]))\n",
    "\n",
    "\n",
    "        return x_hat, elbo\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=(self.lr or self.learning_rate))\n",
    "        lr_scheduler = ReduceLROnPlateau(optimizer,)\n",
    "        return {\n",
    "            \"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler,\n",
    "            \"monitor\": \"val_loss\"\n",
    "        }\n",
    "\n",
    "    def interpolate(self, x1, x2):\n",
    "        assert x1.shape == x2.shape, \"Inputs must be of the same shape\"\n",
    "        if x1.dim() == 3:\n",
    "            x1 = x1.unsqueeze(0)\n",
    "        if x2.dim() == 3:\n",
    "            x2 = x2.unsqueeze(0)\n",
    "        if self.training:\n",
    "            raise Exception(\n",
    "                \"This function should not be called when model is still \"\n",
    "                \"in training mode. Use model.eval() before calling the \"\n",
    "                \"function\")\n",
    "        mu1, lv1 = self.encode(x1)\n",
    "        mu2, lv2 = self.encode(x2)\n",
    "        z1 = self.reparametrize(mu1, lv1)\n",
    "        z2 = self.reparametrize(mu2, lv2)\n",
    "        weights = torch.arange(0.1, 0.9, 0.1)\n",
    "        intermediate = [self.decode(z1)]\n",
    "        for wt in weights:\n",
    "            inter = (1.-wt)*z1 + wt*z2\n",
    "            intermediate.append(self.decode(inter))\n",
    "        intermediate.append(self.decode(z2))\n",
    "        out = torch.stack(intermediate, dim=0).squeeze(1)\n",
    "        return out, (mu1, lv1), (mu2, lv2)\n",
    "\n",
    "    @staticmethod\n",
    "    def custom_transform(normalization):\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/63x61jgj5pvdydkzk62n_9zc0000gn/T/ipykernel_1664/3096799957.py:13: UnderReviewWarning: The feature resnet18_encoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.encoder = resnet18_encoder(False, False)\n",
      "/var/folders/_q/63x61jgj5pvdydkzk62n_9zc0000gn/T/ipykernel_1664/3096799957.py:14: UnderReviewWarning: The feature resnet18_decoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.decoder = resnet18_decoder(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder      | ResNetEncoder | 11.2 M\n",
      "1 | decoder      | ResNetDecoder | 8.6 M \n",
      "2 | fc_mu        | Linear        | 131 K \n",
      "3 | fc_var       | Linear        | 131 K \n",
      "  | other params | n/a           | 1     \n",
      "-----------------------------------------------\n",
      "20.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 M    Total params\n",
      "80.228    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f604e152f664547a2cae489e76ad75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/simenkristoffersen/miniconda3/envs/ml/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = VAE(input_height=24)\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator=\"mps\")\n",
    "trainer.fit(model, trainloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
